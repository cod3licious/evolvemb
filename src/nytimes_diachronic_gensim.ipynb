{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Example using SGNS from gensim\n",
    "\n",
    "Here we create embedding snapshots that can be used in the web app by training a skip-gram with negative sampling (SGNS) word2vec model from the `gensim` library as described in the paper \"Temporal Analysis of Language through Neural Language Models\" by [Kim et. al (2014)](https://arxiv.org/pdf/1405.3515.pdf) (with the only difference that we first train the model on the whole corpus for serveral epochs before training on the individual time periods since the corpus is very very small)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "\n",
    "from evolvemb import PretrainedEmbeddings\n",
    "from evolvemb.diachronic_utils import most_changed_tokens, analyze_emb_over_time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "def load_nyt(start_date=\"2019-01-01\", end_date=\"2020-12-31\"):\n",
    "    # read in NYT dataset\n",
    "    sentences = []\n",
    "    dates = []\n",
    "    with open(\"data/nytimes_dataset.txt\") as f:\n",
    "        for line in f:\n",
    "            d, s = line.strip().split(\"\\t\")\n",
    "            if d < start_date:\n",
    "                continue\n",
    "            elif d > end_date:\n",
    "                break\n",
    "            dates.append(d)\n",
    "            # lowercase! and some longer words mistakenly can end with \".\" due to the tokenizer; remove this!\n",
    "            sentences.append([w if len(w) <= 3 or not w.endswith(\".\") else w[:-1] for w in s.lower().split()])\n",
    "    print(f\"Dataset contains {len(sentences)} sentences between {start_date} and {end_date}\")\n",
    "    return sentences, dates\n",
    "\n",
    "\n",
    "def get_sgns_emb_snapshots(snapshots, start_date=\"2019-01-01\", min_freq=100, saveemb=False):\n",
    "    savepath = f\"data/snapshot_emb_sgns_{start_date}_{snapshots[-1]}_{min_freq}.pkl\"\n",
    "    # see if we can just load the embeddings\n",
    "    if os.path.exists(savepath):\n",
    "        try:\n",
    "            snapshot_emb = pickle.load(open(savepath, \"rb\"))\n",
    "            return snapshot_emb\n",
    "        except Exception as e:\n",
    "            print(\"could not load embeddings:\", e)\n",
    "    # learn embeddings instead\n",
    "    snapshot_emb = {}\n",
    "    # load full dataset\n",
    "    sentences, _ = load_nyt(start_date, snapshots[-1])\n",
    "    random.seed(10)\n",
    "    random.shuffle(sentences)\n",
    "    # train word2vec on whole dataset first (since its really really small)\n",
    "    genw2v = Word2Vec(sentences, size=50, window=5, negative=13, sg=1, iter=100, min_count=min_freq, workers=4)\n",
    "    # keep training on individual time periods\n",
    "    for end_date in snapshots:\n",
    "        # get current batch of sentences\n",
    "        sentences, dates = load_nyt(start_date, end_date)\n",
    "        # train embeddings on these\n",
    "        genw2v.train(sentences, total_examples=len(sentences), epochs=50)\n",
    "        # save embeddings as simple pretrained embeddings\n",
    "        snapshot_emb[dates[-1]] = PretrainedEmbeddings(genw2v.wv).as_simple_pretrained()\n",
    "        start_date = end_date  # only works as expected if end_date > dates[-1]\n",
    "    # reduce file size by ensuring dtype of numpy arrays is float32\n",
    "    for s in snapshot_emb:\n",
    "        snapshot_emb[s].embeddings = np.array(snapshot_emb[s].embeddings, dtype=np.float32)\n",
    "    # possibly save embeddings\n",
    "    if saveemb:\n",
    "        try:\n",
    "            pickle.dump(snapshot_emb, open(savepath, \"wb\"), -1)\n",
    "            print(f\"successfully saved embeddings at {savepath}\")\n",
    "        except Exception as e:\n",
    "            print(\"error saving embeddings:\", e)\n",
    "    return snapshot_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# desired snapshot dates: pre- and post-corona outbreak in detail\n",
    "# snapshot dates with impossible dates so that setting start_date = end_date in \n",
    "# get_sgns_emb_snapshots yields expected results\n",
    "snapshots = [f\"2019-{i:02}-32\" for i in range(6, 13)] + [f\"2020-{i:02}-32\" for i in range(1, 13)]\n",
    "# compute embedding snapshots with SGNS\n",
    "snapshot_emb = get_sgns_emb_snapshots(snapshots, start_date=\"2019-04-01\", min_freq=50, saveemb=True)\n",
    "# save embeddings to use with app.py\n",
    "# pickle.dump(snapshot_emb, open(\"snapshot_emb.pkl\", \"wb\"), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which words have changed the most at some point in the time period\n",
    "most_changed = most_changed_tokens(snapshot_emb)\n",
    "print(\"most changed tokens\")\n",
    "print(\"\\n\".join([f\"{x[0]:15} ({x[1]:.4f})\" for x in most_changed[:25]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create interactive plots for word \"category\"\n",
    "fig_time, fig_pca = analyze_emb_over_time(snapshot_emb, \"category\", savefigs=\"sgns\")\n",
    "fig_time.show()\n",
    "fig_pca.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
